# ğŸš€ å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## 30ç§’å¿«é€Ÿå¼€å§‹

```bash
# 1. è¿›å…¥ç›®å½•
cd code

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. å¿«é€Ÿæµ‹è¯•ï¼ˆæ— éœ€ä¸‹è½½æ•°æ®ï¼‰
python test_quick.py

# 4. å®Œæ•´è¿è¡Œ
python run_pipeline.py --steps all

# 5. æŸ¥çœ‹ç»“æœ
ls data/processed/train.jsonl
```

## é¢„æœŸç»“æœ

è¿è¡Œå®Œæˆåï¼Œä½ ä¼šå¾—åˆ°ï¼š

```
data/processed/
â”œâ”€â”€ train.jsonl       # ~540 è®­ç»ƒæ ·æœ¬
â”œâ”€â”€ val.jsonl         # ~60 éªŒè¯æ ·æœ¬
â””â”€â”€ plots/            # ç»Ÿè®¡å›¾è¡¨
    â”œâ”€â”€ chunks_per_proof.png
    â”œâ”€â”€ chunk_lengths.png
    â””â”€â”€ length_distributions.png
```

## æ ·æœ¬ç¤ºä¾‹

æ‰“å¼€ `train.jsonl` ä¼šçœ‹åˆ°ï¼š

```json
{
  "messages": [
    {
      "role": "user",
      "content": "Theorem:\ntheorem add_comm...\n\nPrevious progress:\n...\n\nContinue:"
    },
    {
      "role": "assistant",
      "content": "<proof>\ninduction a with\n...\n</proof>"
    }
  ]
}
```

## ä¸‹ä¸€æ­¥

1. **æ£€æŸ¥æ•°æ®è´¨é‡**
   ```bash
   python data_preparation/analyze_data.py
   ```

2. **è°ƒæ•´é…ç½®**
   - ç¼–è¾‘ `config.yaml`
   - ä¿®æ”¹åˆ‡åˆ†ç­–ç•¥ã€å—å¤§å°ç­‰

3. **æ¨¡å‹è®­ç»ƒ**
   - ä½¿ç”¨ `train.jsonl` å’Œ `val.jsonl`
   - å‚è€ƒ README.md çš„è®­ç»ƒç¤ºä¾‹

## å¸¸è§é—®é¢˜

**Q: ä¸‹è½½å¾ˆæ…¢ï¼Ÿ**
A: æ­£å¸¸ï¼Œæ•°æ®é›†è¾ƒå¤§ã€‚å¯ä»¥å…ˆè¿è¡Œ `test_quick.py` æµ‹è¯•ã€‚

**Q: æƒ³è¦æ›´å¤šæ•°æ®ï¼Ÿ**
A: ä¿®æ”¹ `config.yaml` ä¸­çš„ `dataset.splits: ["valid", "test"]`

**Q: åˆ‡åˆ†æ•ˆæœä¸å¥½ï¼Ÿ**
A: è¯•è¯•ä¸åŒç­–ç•¥ï¼š
```bash
python run_pipeline.py --strategy syntax_based
```

## éœ€è¦å¸®åŠ©ï¼Ÿ

- ğŸ“– è¯¦ç»†æ–‡æ¡£: `README.md`
- ğŸ“ é¡¹ç›®æ¦‚è§ˆ: `PROJECT_OVERVIEW.md`
- ğŸ§ª æµ‹è¯•ä»£ç : `test_quick.py`
- âš™ï¸ é…ç½®è¯´æ˜: `config.yaml` (æœ‰æ³¨é‡Š)

---

**å¼€å§‹æ„‰å¿«çš„å®éªŒå§ï¼** ğŸ‰
