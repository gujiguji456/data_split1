#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ä¸ä¸‹è½½æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•æµç¨‹
"""

import sys
from pathlib import Path
import yaml
import json

sys.path.insert(0, str(Path(__file__).parent))

from data_preparation.chunk_proofs import ProofChunker
from data_preparation.build_training_data import TrainingDataBuilder


def create_mock_examples():
    """åˆ›å»ºæ¨¡æ‹Ÿæ ·æœ¬"""
    return [
        {
            'id': 0,
            'theorem': 'theorem add_comm (a b : â„•) : a + b = b + a := by',
            'proof': '''by
  intro a b
  induction a with
  | zero =>
    simp
    apply Nat.zero_add
  | succ n ih =>
    rw [Nat.succ_add]
    rw [ih]
    rw [Nat.add_succ]
    rfl''',
            'split': 'test'
        },
        {
            'id': 1,
            'theorem': 'theorem mul_comm (a b : â„•) : a * b = b * a := by',
            'proof': '''by
  intro a b
  induction a with
  | zero => simp
  | succ n ih =>
    rw [Nat.succ_mul]
    rw [ih]
    rw [Nat.mul_succ]
    ring''',
            'split': 'test'
        },
        {
            'id': 2,
            'theorem': 'theorem fermat_little (p : â„•) (hp : Prime p) (a : â„•) : p âˆ£ (a^p - a) := by',
            'proof': '''by
  intro p hp a
  induction a with
  | zero =>
    simp
    apply dvd_zero
  | succ n ih =>
    have h1 : p âˆ£ (n^p - n) := ih
    have h2 : p âˆ£ p * n^(p-1) := dvd_mul_right p (n^(p-1))
    rw [Nat.succ_eq_add_one]
    rw [Nat.add_pow]
    ring_nf
    apply dvd_add
    Â· exact h1
    Â· apply dvd_mul_of_dvd_each_mul_of_dvd_sub
      Â· exact h2
      Â· apply Nat.Prime.dvd_factorial
        exact hp
        linarith''',
            'split': 'test'
        }
    ]


def test_chunking(config):
    """æµ‹è¯•åˆ‡åˆ†åŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: è¯æ˜åˆ‡åˆ†")
    print("="*60)

    examples = create_mock_examples()
    chunker = ProofChunker(config)

    for ex in examples:
        print(f"\n--- æµ‹è¯•æ ·æœ¬ {ex['id']} ---")
        print(f"å®šç†: {ex['theorem'][:60]}...")

        chunks = chunker.chunk_proof(ex['proof'], ex['theorem'])

        print(f"åˆ‡åˆ†ç»“æœ: {len(chunks)} å—")
        for chunk in chunks:
            print(f"  Chunk {chunk['chunk_id']}: lines {chunk['start_line']}-{chunk['end_line']}")
            print(f"    å†…å®¹å‰50å­—: {chunk['content'][:50]}...")

            # æµ‹è¯•æ‘˜è¦
            summary = chunker.extract_summary(chunk)
            print(f"    å¤´éƒ¨æ‘˜è¦: {summary['head'][:30]}...")
            print(f"    å°¾éƒ¨æ‘˜è¦: {summary['tail'][-30:]}...")

    print("\nâœ… åˆ‡åˆ†æµ‹è¯•é€šè¿‡!")


def test_training_data(config):
    """æµ‹è¯•è®­ç»ƒæ•°æ®æ„é€ """
    print("\n" + "="*60)
    print("æµ‹è¯•2: è®­ç»ƒæ•°æ®æ„é€ ")
    print("="*60)

    examples = create_mock_examples()
    builder = TrainingDataBuilder(config)

    all_samples = []
    for ex in examples:
        samples = builder.build_samples_for_proof(ex)
        all_samples.extend(samples)

        print(f"\n--- æ ·æœ¬ {ex['id']} ---")
        print(f"åŸå§‹è¯æ˜: {len(ex['proof'].split())} è¡Œ")
        print(f"ç”Ÿæˆæ ·æœ¬: {len(samples)} ä¸ª")

        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ ·æœ¬
        if samples:
            sample = samples[0]
            print(f"\nç¬¬ä¸€ä¸ªæ ·æœ¬é¢„è§ˆ:")
            print(f"  Chunk ID: {sample['metadata']['chunk_id']}")
            print(f"  Total Chunks: {sample['metadata']['total_chunks']}")

            user_msg = sample['messages'][0]['content']
            asst_msg = sample['messages'][1]['content']

            print(f"\n  User message (å‰100å­—):")
            print(f"    {user_msg[:100]}...")

            print(f"\n  Assistant message (å‰100å­—):")
            print(f"    {asst_msg[:100]}...")

    print(f"\næ€»è®¡ç”Ÿæˆ {len(all_samples)} ä¸ªè®­ç»ƒæ ·æœ¬")

    # ä¿å­˜æµ‹è¯•æ•°æ®
    output_file = Path("./output/test_samples.jsonl")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        for sample in all_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')

    print(f"\nğŸ’¾ æµ‹è¯•æ ·æœ¬å·²ä¿å­˜åˆ°: {output_file}")
    print("\nâœ… è®­ç»ƒæ•°æ®æ„é€ æµ‹è¯•é€šè¿‡!")


def test_strategies(config):
    """æµ‹è¯•ä¸åŒåˆ‡åˆ†ç­–ç•¥"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: ä¸åŒåˆ‡åˆ†ç­–ç•¥å¯¹æ¯”")
    print("="*60)

    example = create_mock_examples()[2]  # ä½¿ç”¨æœ€é•¿çš„è¯æ˜
    strategies = ['line_based', 'syntax_based', 'token_based']

    for strategy in strategies:
        print(f"\n--- {strategy} ---")
        config['chunking']['strategy'] = strategy
        chunker = ProofChunker(config)

        chunks = chunker.chunk_proof(example['proof'], example['theorem'])
        print(f"  åˆ‡åˆ†å—æ•°: {len(chunks)}")
        for chunk in chunks:
            lines = chunk['content'].split('\n')
            print(f"    Chunk {chunk['chunk_id']}: {len(lines)} è¡Œ")

    print("\nâœ… ç­–ç•¥å¯¹æ¯”æµ‹è¯•é€šè¿‡!")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("Lean4 Delethink å¿«é€Ÿæµ‹è¯•")
    print("="*60)

    # åŠ è½½é…ç½®
    config_path = Path(__file__).parent / "config.yaml"
    with open(config_path) as f:
        config = yaml.safe_load(f)

    try:
        # è¿è¡Œæµ‹è¯•
        test_chunking(config)
        test_training_data(config)
        test_strategies(config)

        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*60)

        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œå®Œæ•´æµç¨‹: python run_pipeline.py --steps all")
        print("  2. æŸ¥çœ‹æµ‹è¯•è¾“å‡º: output/test_samples.jsonl")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
