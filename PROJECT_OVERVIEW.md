# Lean4 Delethink æ•°æ®å‡†å¤‡å·¥å…· - é¡¹ç›®æ¦‚è§ˆ

## ğŸ¯ é¡¹ç›®ç›®æ ‡

å°† Lean4 å½¢å¼åŒ–è¯æ˜åˆ‡åˆ†æˆå—ï¼ˆchunksï¼‰ï¼Œæ„é€ è®­ç»ƒæ•°æ®ï¼Œç”¨äºè®­ç»ƒèƒ½å¤Ÿ"åˆ†å—æ¨ç†"çš„å°å‹è¯­è¨€æ¨¡å‹ã€‚

## ğŸ§  æ ¸å¿ƒæ€æƒ³

**Delethink åˆ†å—æ¨ç†æ¨¡å¼ï¼š**

```
ä¼ ç»Ÿæ–¹æ³•ï¼ˆLongCoTï¼‰:
  é—®é¢˜ â†’ ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è¯æ˜ (5000+ tokens)

Delethink æ–¹æ³•:
  é—®é¢˜ â†’ ç”Ÿæˆç¬¬1å— (2000 tokens)
       â†’ æ€»ç»“å…³é”®ä¿¡æ¯ï¼ˆå¤´éƒ¨+å°¾éƒ¨ï¼‰
       â†’ åŸºäºæ‘˜è¦ç”Ÿæˆç¬¬2å— (2000 tokens)
       â†’ æ€»ç»“å…³é”®ä¿¡æ¯
       â†’ åŸºäºæ‘˜è¦ç”Ÿæˆç¬¬3å— (1000 tokens)
       â†’ å®Œæˆè¯æ˜ âœ“

ä¼˜åŠ¿ï¼š
  - å›ºå®šä¸Šä¸‹æ–‡çª—å£ï¼ˆO(n) vs O(nÂ²)ï¼‰
  - æ¨¡å‹å­¦ä¼šä¿¡æ¯å‹ç¼©å’Œä¼ é€’
  - é€‚åˆå°æ¨¡å‹ï¼ˆ1.8Bï¼‰è®­ç»ƒ
```

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
code/
â”œâ”€â”€ config.yaml                   # ğŸ“‹ æ ¸å¿ƒé…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt              # ğŸ“¦ Pythonä¾èµ–
â”œâ”€â”€ run_pipeline.py              # ğŸš€ ä¸€é”®è¿è¡Œè„šæœ¬
â”œâ”€â”€ test_quick.py                # ğŸ§ª å¿«é€Ÿæµ‹è¯•è„šæœ¬
â”œâ”€â”€ README.md                    # ğŸ“– ä½¿ç”¨æ–‡æ¡£
â”œâ”€â”€ PROJECT_OVERVIEW.md          # ğŸ“ æœ¬æ–‡ä»¶
â”‚
â”œâ”€â”€ data_preparation/            # æ ¸å¿ƒå¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ download_data.py         # ä¸‹è½½ MiniF2F-Lean4
â”‚   â”œâ”€â”€ chunk_proofs.py          # è¯æ˜åˆ‡åˆ†ï¼ˆ3ç§ç­–ç•¥ï¼‰
â”‚   â”œâ”€â”€ build_training_data.py   # æ„é€ è®­ç»ƒæ ·æœ¬
â”‚   â””â”€â”€ analyze_data.py          # æ•°æ®ç»Ÿè®¡åˆ†æ
â”‚
â”œâ”€â”€ utils/                       # å·¥å…·æ¨¡å—ï¼ˆé¢„ç•™ï¼‰
â”‚
â”œâ”€â”€ data/                        # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                     # åŸå§‹æ•°æ®
â”‚   â”‚   â”œâ”€â”€ valid_raw.jsonl
â”‚   â”‚   â””â”€â”€ valid_filtered.jsonl
â”‚   â””â”€â”€ processed/               # è®­ç»ƒæ•°æ®
â”‚       â”œâ”€â”€ train.jsonl          # â­ è®­ç»ƒé›†
â”‚       â”œâ”€â”€ val.jsonl            # â­ éªŒè¯é›†
â”‚       â””â”€â”€ plots/               # ç»Ÿè®¡å›¾è¡¨
â”‚
â””â”€â”€ output/                      # æµ‹è¯•è¾“å‡º
```

## âš™ï¸ ä¸‰ç§åˆ‡åˆ†ç­–ç•¥

| ç­–ç•¥ | æè¿° | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|------|
| **line_based** | æŒ‰è¡Œæ•°å‡åŒ€åˆ‡åˆ† | ç®€å•å¯é  | å¯èƒ½æ‰“æ–­è¯­ä¹‰ |
| **syntax_based** | åœ¨å…³é”®è¯å¤„åˆ‡åˆ†<br>(have, cases, induction) | ç¬¦åˆè¯­ä¹‰è¾¹ç•Œ | å¯èƒ½è¯†åˆ«å¤±è´¥ |
| **token_based** | æŒ‰tokenæ•°å›ºå®šåˆ‡åˆ† | ç²¾ç¡®æ§åˆ¶é•¿åº¦ | ç®€åŒ–å®ç° |

## ğŸ”„ å®Œæ•´æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å‡†å¤‡æµç¨‹                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ­¥éª¤1: ä¸‹è½½æ•°æ®
  â””â”€> ä» HuggingFace ä¸‹è½½ MiniF2F-Lean4
  â””â”€> è¿‡æ»¤æ— æ•ˆè¯æ˜ï¼ˆç©ºã€å¤ªé•¿ã€æœ‰sorryç­‰ï¼‰
  â””â”€> è¾“å‡º: valid_filtered.jsonl, test_filtered.jsonl

æ­¥éª¤2: åˆ‡åˆ†è¯æ˜
  â””â”€> é€‰æ‹©åˆ‡åˆ†ç­–ç•¥ï¼ˆline/syntax/tokenï¼‰
  â””â”€> å°†æ¯ä¸ªè¯æ˜åˆ‡æˆ N å—
  â””â”€> ä¸ºæ¯å—æå–æ‘˜è¦ï¼ˆå¤´éƒ¨+å°¾éƒ¨ï¼‰

æ­¥éª¤3: æ„é€ è®­ç»ƒæ ·æœ¬
  â””â”€> ç¬¬1å—ï¼šè¾“å…¥=å®šç†å£°æ˜ï¼Œè¾“å‡º=ç¬¬1å—å†…å®¹
  â””â”€> ç¬¬2å—ï¼šè¾“å…¥=å®šç†+ç¬¬1å—æ‘˜è¦ï¼Œè¾“å‡º=ç¬¬2å—å†…å®¹
  â””â”€> ç¬¬Nå—ï¼šè¾“å…¥=å®šç†+å†å²æ‘˜è¦ï¼Œè¾“å‡º=ç¬¬Nå—å†…å®¹
  â””â”€> è¾“å‡º: train.jsonl, val.jsonl

æ­¥éª¤4: æ•°æ®åˆ†æ
  â””â”€> ç»Ÿè®¡å—æ•°åˆ†å¸ƒã€é•¿åº¦åˆ†å¸ƒ
  â””â”€> ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
  â””â”€> å±•ç¤ºæ ·æœ¬ç¤ºä¾‹
```

## ğŸ“Š é¢„æœŸè¾“å‡º

### æ•°æ®è§„æ¨¡ï¼ˆåŸºäº MiniF2F Valid Setï¼‰

```
åŸå§‹æ•°æ®: 244 ä¸ªå®šç†
è¿‡æ»¤å: ~200 ä¸ªå®šç†ï¼ˆå»é™¤å¤ªçŸ­/å¤ªé•¿/æœ‰sorryï¼‰
è®­ç»ƒæ ·æœ¬: ~600 ä¸ªï¼ˆå¹³å‡æ¯ä¸ªå®šç†3å—ï¼‰

è®­ç»ƒé›†: ~540 æ ·æœ¬ (90%)
éªŒè¯é›†: ~60 æ ·æœ¬ (10%)
```

### æ ·æœ¬æ ¼å¼ç¤ºä¾‹

```json
{
  "messages": [
    {
      "role": "user",
      "content": "You are a Lean4 theorem prover...\n\nTheorem:\ntheorem add_comm (a b : â„•) : a + b = b + a := by\n\nPrevious progress:\nby\n  intro a b\n...\n<continue>\n\nContinue the proof:"
    },
    {
      "role": "assistant",
      "content": "<proof>\ninduction a with\n| zero => simp\n| succ n ih => rw [Nat.succ_add]; rw [ih]\n</proof>"
    }
  ],
  "metadata": {
    "chunk_id": 1,
    "total_chunks": 3,
    "is_first_chunk": false,
    "is_last_chunk": false,
    "example_id": 42
  }
}
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
cd code
pip install -r requirements.txt
```

### 2. æµ‹è¯•ï¼ˆä¸ä¸‹è½½æ•°æ®ï¼‰

```bash
python test_quick.py
```

é¢„æœŸè¾“å‡ºï¼š
```
æµ‹è¯•1: è¯æ˜åˆ‡åˆ† âœ“
æµ‹è¯•2: è®­ç»ƒæ•°æ®æ„é€  âœ“
æµ‹è¯•3: ä¸åŒåˆ‡åˆ†ç­–ç•¥å¯¹æ¯” âœ“
```

### 3. å®Œæ•´è¿è¡Œ

```bash
python run_pipeline.py --steps all
```

é¢„æœŸæ—¶é—´ï¼š
- ä¸‹è½½æ•°æ®: ~2-5åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰
- æ„é€ æ•°æ®: ~1-2åˆ†é’Ÿ
- åˆ†ææ•°æ®: ~1åˆ†é’Ÿ
- **æ€»è®¡: ~5-10åˆ†é’Ÿ**

### 4. æ£€æŸ¥è¾“å‡º

```bash
ls data/processed/
# åº”è¯¥çœ‹åˆ°:
#   train.jsonl (è®­ç»ƒé›†)
#   val.jsonl (éªŒè¯é›†)
#   plots/ (ç»Ÿè®¡å›¾è¡¨)
```

## ğŸ“ ä¸‹ä¸€æ­¥ï¼šæ¨¡å‹è®­ç»ƒ

ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è¿›è¡Œ SFT è®­ç»ƒï¼š

```python
# ä¼ªä»£ç 
from transformers import AutoModelForCausalLM, Trainer
from datasets import load_dataset

# 1. åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "internlm/internlm2-math-plus-1_8b"
)

# 2. åŠ è½½æ•°æ®
dataset = load_dataset('json', data_files={
    'train': 'data/processed/train.jsonl',
    'validation': 'data/processed/val.jsonl'
})

# 3. è®­ç»ƒï¼ˆä½¿ç”¨ LoRAï¼‰
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(r=32, lora_alpha=16)
model = get_peft_model(model, lora_config)

# 4. å¼€å§‹è®­ç»ƒ
trainer = Trainer(model=model, train_dataset=dataset['train'], ...)
trainer.train()
```

é¢„æœŸè®­ç»ƒæ—¶é—´ï¼š
- GPU: 1x A100 (40GB)
- æ•°æ®: ~600 æ ·æœ¬
- Epochs: 3-5
- **æ—¶é—´: 2-4å°æ—¶**

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

```bash
# åªä¸‹è½½æ•°æ®
python run_pipeline.py --steps download

# åªæ„é€ è®­ç»ƒæ•°æ®
python run_pipeline.py --steps build

# åªåˆ†ææ•°æ®
python run_pipeline.py --steps analyze

# ä½¿ç”¨ç‰¹å®šç­–ç•¥
python run_pipeline.py --strategy syntax_based

# è‡ªå®šä¹‰é…ç½®
python run_pipeline.py --config my_config.yaml
```

## ğŸ“ˆ å…³é”®é…ç½®å‚æ•°

ç¼–è¾‘ `config.yaml`ï¼š

```yaml
# 1. åˆ‡åˆ†ç­–ç•¥
chunking:
  strategy: "line_based"  # æ”¹æˆ "syntax_based" è¯•è¯•

  line_based:
    target_chunks: 3      # æ”¹æˆ 2 æˆ– 4

# 2. Delethink å‚æ•°
delethink:
  keep_head: 100          # ä¿ç•™çš„å¤´éƒ¨è¡Œæ•°
  keep_tail: 20           # ä¿ç•™çš„å°¾éƒ¨è¡Œæ•°

# 3. è¿‡æ»¤è§„åˆ™
filtering:
  min_proof_length: 10    # æœ€çŸ­è¯æ˜ï¼ˆè¡Œï¼‰
  max_proof_length: 200   # æœ€é•¿è¯æ˜ï¼ˆè¡Œï¼‰
  skip_sorry: true        # è·³è¿‡æœªå®Œæˆè¯æ˜

# 4. è®­ç»ƒé›†æ¯”ä¾‹
training:
  train_split_ratio: 0.9  # 90% è®­ç»ƒï¼Œ10% éªŒè¯
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: ä¸‹è½½å¤±è´¥

```bash
âŒ Error: Connection timeout

è§£å†³æ–¹æ¡ˆ:
  1. æ£€æŸ¥ç½‘ç»œè¿æ¥
  2. è®¾ç½®ä»£ç†: export HTTP_PROXY=...
  3. æˆ–æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†æ”¾åˆ° data/raw/
```

### é—®é¢˜2: åˆ‡åˆ†ç»“æœä¸ºç©º

```bash
âš ï¸  Generated 0 training samples

è§£å†³æ–¹æ¡ˆ:
  1. æ£€æŸ¥è¿‡æ»¤æ¡ä»¶æ˜¯å¦å¤ªä¸¥æ ¼
  2. æ”¾å®½ min_proof_length
  3. å°è¯•ä¸åŒçš„åˆ‡åˆ†ç­–ç•¥
```

### é—®é¢˜3: å†…å­˜ä¸è¶³

```bash
âŒ MemoryError

è§£å†³æ–¹æ¡ˆ:
  1. å‡å°‘ target_chunks
  2. å¢åŠ  min_lines_per_chunk
  3. åˆ†æ‰¹å¤„ç†æ•°æ®
```

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### Delethink æ‘˜è¦æå–

```python
def extract_summary(chunk):
    """
    ä¿ç•™å¤´éƒ¨å’Œå°¾éƒ¨ï¼Œåˆ é™¤ä¸­é—´

    è¾“å…¥:
      by
        intro a b
        induction a with
        | zero => simp [10è¡Œ]
        | succ n ih => ... [30è¡Œ]
        rw [Nat.add_comm]

    è¾“å‡º:
      å¤´éƒ¨ (keep_head=10è¡Œ):
        by
          intro a b
          induction a with
          | zero => simp
          ...

      å°¾éƒ¨ (keep_tail=20è¡Œ):
        ...
        | succ n ih =>
          rw [Nat.succ_add]
          rw [Nat.add_comm]
    """
```

### è®­ç»ƒæ ·æœ¬æ„é€ é€»è¾‘

```python
for chunk in chunks:
    if chunk.is_first:
        context = ""  # ç¬¬ä¸€å—æ— ä¸Šä¸‹æ–‡
    else:
        context = summarize(previous_chunks)  # å†å²æ‘˜è¦

    sample = {
        'input': theorem + context,
        'output': chunk.content
    }
```

## ğŸ¯ è¯„ä¼°æŒ‡æ ‡ï¼ˆä¾›å‚è€ƒï¼‰

è®­ç»ƒåï¼Œè¯„ä¼°æ¨¡å‹çš„åˆ†å—èƒ½åŠ›ï¼š

```python
æŒ‡æ ‡1: è¯­æ³•æ­£ç¡®ç‡
  - ç”Ÿæˆçš„ Lean4 ä»£ç èƒ½å¦ç¼–è¯‘

æŒ‡æ ‡2: è¿è´¯æ€§
  - å—ä¸å—ä¹‹é—´æ˜¯å¦é€»è¾‘è¿è´¯

æŒ‡æ ‡3: å®Œæ•´æ€§
  - æ‹¼æ¥æ‰€æœ‰å—åèƒ½å¦å®Œæˆè¯æ˜

æŒ‡æ ‡4: æ•ˆç‡
  - ç”Ÿæˆé€Ÿåº¦å’Œèµ„æºæ¶ˆè€—
```

## ğŸ“ è”ç³»æ–¹å¼

æœ‰é—®é¢˜ï¼Ÿ
- æŸ¥çœ‹ README.md è¯¦ç»†æ–‡æ¡£
- è¿è¡Œ test_quick.py å¿«é€Ÿæµ‹è¯•
- æŸ¥çœ‹ä»£ç æ³¨é‡Š

---

**ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€**
